{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 00m 08s]\n",
      "val_binary_accuracy: 0.7118947505950928\n",
      "\n",
      "Best val_binary_accuracy So Far: 0.7118947505950928\n",
      "Total elapsed time: 00h 00m 18s\n"
     ]
    }
   ],
   "source": [
    "# Import helps\n",
    "from src.helpers import *\n",
    "\n",
    "# Import base\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Feature selection\n",
    "from boruta import BorutaPy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Dimentionality reduction\n",
    "from umap import UMAP\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Keras tuner\n",
    "import keras_tuner\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Clear any backend\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "# Reload the saved scaled data\n",
    "X_train = pd.read_csv('data/train/scaled_X_train.csv',\n",
    "                      parse_dates=True, index_col='unix')\n",
    "y_train = pd.read_csv('data/train/y_train.csv',\n",
    "                      parse_dates=True, index_col='unix')\n",
    "X_test = pd.read_csv('data/test/scaled_X_test.csv',\n",
    "                     parse_dates=True, index_col='unix')\n",
    "y_test = pd.read_csv('data/test/y_test.csv',\n",
    "                     parse_dates=True, index_col='unix')\n",
    "X_val = pd.read_csv('data/val/scaled_X_val.csv',\n",
    "                    parse_dates=True, index_col='unix')\n",
    "y_val = pd.read_csv('data/val/y_val.csv', parse_dates=True, index_col='unix')\n",
    "\n",
    "# Calculate the weights for the imbalanced classes\n",
    "y = pd.concat([y_train, y_val, y_test])\n",
    "weights = cwts(y.values.flatten())\n",
    "\n",
    "# Metrics\n",
    "binary_accuracy = tf.keras.metrics.BinaryAccuracy()\n",
    "precision = tf.keras.metrics.Precision()\n",
    "recall = tf.keras.metrics.Recall()\n",
    "\n",
    "# Run the pipeline\n",
    "corr = RemoveCorPairwiseTransform()\n",
    "rf = RandomForestClassifier(n_jobs=-1, class_weight=weights)\n",
    "boruta = BorutaPy(rf, n_estimators='auto', verbose=2, perc=90)\n",
    "umap = UMAP(n_neighbors=10)\n",
    "pipe = Pipeline([('pairwisecorr', corr), ('boruta', boruta), ('umap', umap)], verbose=True)\n",
    "\n",
    "X_train_pipe = pipe.fit_transform(X_train, y_train.values.ravel())\n",
    "X_val_pipe = pipe.transform(X_val)\n",
    "\n",
    "# Calculate feature length\n",
    "featurelen = X_train_pipe.shape[-1]\n",
    "\n",
    "# An extension of the keras tuner HyperModel that allows for iterating over different model functions\n",
    "\n",
    "\n",
    "class IterableHyperModel(keras_tuner.HyperModel):\n",
    "    def __init__(self, inputs, model_func, name=None, tunable=True):\n",
    "        self.inputs = inputs\n",
    "        self.model_func = model_func\n",
    "\n",
    "    def build(self, hp):\n",
    "        # Define the hyperparameters\n",
    "        # Units\n",
    "        units_1 = hp.Int('units_1', min_value=16, max_value=512, step=16)\n",
    "        units_2 = hp.Int('units_2', min_value=16, max_value=512, step=16)\n",
    "        units_3 = hp.Int('units_3', min_value=16, max_value=512, step=16)\n",
    "        # Learning rate\n",
    "        lr = hp.Float('learning_rate', min_value=0.05, max_value=0.5)\n",
    "        # Dropout rate\n",
    "        dr = hp.Float('dropout_rate', min_value=0.01, max_value=0.8)\n",
    "        # Optimizer\n",
    "        hp_optimizer = hp.Choice('optimizer', ['adam', 'rmsprop', 'adagrad'])\n",
    "        if hp_optimizer == 'adam':\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "        elif hp_optimizer == 'rmsprop':\n",
    "            optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
    "        elif hp_optimizer == 'adagrad':\n",
    "            optimizer = tf.keras.optimizers.Adagrad(learning_rate=lr)\n",
    "\n",
    "        # Activations\n",
    "        activation_1 = hp.Choice(\n",
    "            'activation_1', ['relu', 'elu', 'tanh', 'sigmoid', 'selu'])\n",
    "        activation_2 = hp.Choice(\n",
    "            'activation_2', ['relu', 'elu', 'tanh', 'sigmoid', 'selu'])\n",
    "        activation_3 = hp.Choice(\n",
    "            'activation_3', ['relu', 'elu', 'tanh', 'sigmoid', 'selu'])\n",
    "\n",
    "        model = self.model_func(self.inputs, units_1, units_2, units_3, dr, optimizer, activation_1, activation_2, activation_3)\n",
    "        return model\n",
    "\n",
    "# Begin defining models\n",
    "# Three mayer model with dropout\n",
    "def two_layer_dropout(inputs, units_1, units_2, units_3, dr, optimizer, activation_1, activation_2, activation_3):\n",
    "            \n",
    "    # Initialise layers\n",
    "    x = tf.keras.layers.LSTM(units=units_1, activation=activation_1, dropout=dr, recurrent_dropout=dr,return_sequences=True, name='lstm-1-twolayer-dropout')(inputs)\n",
    "    x = tf.keras.layers.LSTM(units=units_2, activation=activation_2, dropout=dr, recurrent_dropout=dr,name='lstm-3-twolayer-dropout')(x)\n",
    "    outputs = tf.keras.layers.Dense(units=1, activation='sigmoid', name='dense-twolayer-dropout')(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy',\n",
    "                      weighted_metrics=[binary_accuracy, precision, recall])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Define the sequence length and reshape the data into the correct array\n",
    "seqlen = 1\n",
    "name = 'two_layer_dropout'\n",
    "\n",
    "# Define the tensors\n",
    "train_tensors = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    X_train_pipe, y_train.iloc[seqlen-1:], seqlen)\n",
    "val_tensors = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    X_val_pipe, y_val.iloc[seqlen-1:], seqlen)\n",
    "\n",
    "# Define the input\n",
    "inputs = tf.keras.Input(shape=(seqlen, featurelen))\n",
    "\n",
    "# Define the file paths\n",
    "filepath = f'./tensorboard/model_tuning/{name}_{seqlen}_hour'\n",
    "modelpath = f'./models/model_tuning/{name}_{seqlen}_hour'\n",
    "\n",
    "# Define the callbacks\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        patience=10, monitor='val_binary_accuracy', mode='max'),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=filepath, histogram_freq=1),\n",
    "    tf.keras.callbacks.ModelCheckpoint(modelpath, monitor='val_binary_accuracy', save_best_only=True, mode='max')]\n",
    "\n",
    "# Initialise tuner and search\n",
    "\n",
    "tuner = keras_tuner.Hyperband(IterableHyperModel(inputs, two_layer_dropout), objective=keras_tuner.Objective(\n",
    "    'val_binary_accuracy', direction='max'), max_epochs=2, overwrite=True, directory=modelpath, seed=42, project_name=f'{name}_{seqlen}_hour')\n",
    "\n",
    "tuner.search(train_tensors, validation_data=val_tensors,\n",
    "             callbacks=callbacks, epochs=1000, class_weight=weights, use_multiprocessing=True, workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm-1-twolayer-dropout will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm-1-twolayer-dropout will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm-3-twolayer-dropout will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm-3-twolayer-dropout will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.src.engine.functional.Functional object at 0x7bce2f6c7a30>\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('hello.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm-1-twolayer-dropout will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm-1-twolayer-dropout will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm-3-twolayer-dropout will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm-3-twolayer-dropout will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:absl:Skipping variable loading for optimizer 'RMSprop', because it has 9 variables whereas the saved optimizer has 1 variables. \n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.saving.load_model('./models/final_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'model',\n",
       " 'trainable': True,\n",
       " 'layers': [{'module': 'keras.layers',\n",
       "   'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, 1, 159),\n",
       "    'dtype': 'float32',\n",
       "    'sparse': False,\n",
       "    'ragged': False,\n",
       "    'name': 'input_1'},\n",
       "   'registered_name': None,\n",
       "   'name': 'input_1',\n",
       "   'inbound_nodes': []},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'LSTM',\n",
       "   'config': {'name': 'lstm-1-twolayer-dropout',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'return_sequences': True,\n",
       "    'return_state': False,\n",
       "    'go_backwards': False,\n",
       "    'stateful': False,\n",
       "    'unroll': False,\n",
       "    'time_major': False,\n",
       "    'units': 336,\n",
       "    'activation': 'tanh',\n",
       "    'recurrent_activation': 'sigmoid',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None},\n",
       "     'registered_name': None},\n",
       "    'recurrent_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'Orthogonal',\n",
       "     'config': {'gain': 1.0, 'seed': None},\n",
       "     'registered_name': None},\n",
       "    'bias_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'Zeros',\n",
       "     'config': {},\n",
       "     'registered_name': None},\n",
       "    'unit_forget_bias': True,\n",
       "    'kernel_regularizer': None,\n",
       "    'recurrent_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'recurrent_constraint': None,\n",
       "    'bias_constraint': None,\n",
       "    'dropout': 0.7117317803974657,\n",
       "    'recurrent_dropout': 0.7117317803974657,\n",
       "    'implementation': 1},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 1, 159)},\n",
       "   'name': 'lstm-1-twolayer-dropout',\n",
       "   'inbound_nodes': [[['input_1', 0, 0, {}]]]},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'LSTM',\n",
       "   'config': {'name': 'lstm-3-twolayer-dropout',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'return_sequences': False,\n",
       "    'return_state': False,\n",
       "    'go_backwards': False,\n",
       "    'stateful': False,\n",
       "    'unroll': False,\n",
       "    'time_major': False,\n",
       "    'units': 32,\n",
       "    'activation': 'relu',\n",
       "    'recurrent_activation': 'sigmoid',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None},\n",
       "     'registered_name': None},\n",
       "    'recurrent_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'Orthogonal',\n",
       "     'config': {'gain': 1.0, 'seed': None},\n",
       "     'registered_name': None},\n",
       "    'bias_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'Zeros',\n",
       "     'config': {},\n",
       "     'registered_name': None},\n",
       "    'unit_forget_bias': True,\n",
       "    'kernel_regularizer': None,\n",
       "    'recurrent_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'recurrent_constraint': None,\n",
       "    'bias_constraint': None,\n",
       "    'dropout': 0.7117317803974657,\n",
       "    'recurrent_dropout': 0.7117317803974657,\n",
       "    'implementation': 1},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 1, 336)},\n",
       "   'name': 'lstm-3-twolayer-dropout',\n",
       "   'inbound_nodes': [[['lstm-1-twolayer-dropout', 0, 0, {}]]]},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'Dense',\n",
       "   'config': {'name': 'dense-twolayer-dropout',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 1,\n",
       "    'activation': 'sigmoid',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None},\n",
       "     'registered_name': None},\n",
       "    'bias_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'Zeros',\n",
       "     'config': {},\n",
       "     'registered_name': None},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 32)},\n",
       "   'name': 'dense-twolayer-dropout',\n",
       "   'inbound_nodes': [[['lstm-3-twolayer-dropout', 0, 0, {}]]]}],\n",
       " 'input_layers': [['input_1', 0, 0]],\n",
       " 'output_layers': [['dense-twolayer-dropout', 0, 0]]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "time_str = datetime.now().strftime('%m-%d-%Y-%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/baseline_model_01-13-2024-19:00:41.keras',\n",
       " './models/final_model_01-13-2024-18:18:32.keras']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "models = glob.glob('./models/*.keras')\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_fp, final_model_fp = glob.glob('./models/*.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./models/baseline_model_01-13-2024-19:00:41.keras'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./models/final_model_01-13-2024-18:18:32.keras'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model_fp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_assignment_code-eTELY0YF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
