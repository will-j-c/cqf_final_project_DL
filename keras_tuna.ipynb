{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 00m 11s]\n",
      "val_binary_accuracy: 0.23263157904148102\n",
      "\n",
      "Best val_binary_accuracy So Far: 0.23263157904148102\n",
      "Total elapsed time: 00h 00m 21s\n"
     ]
    }
   ],
   "source": [
    "# Import helps\n",
    "from src.helpers import *\n",
    "\n",
    "# Import base\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Feature selection\n",
    "from boruta import BorutaPy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Dimentionality reduction\n",
    "from umap import UMAP\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Keras tuner\n",
    "import keras_tuner\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Clear any backend\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "# Reload the saved scaled data\n",
    "X_train = pd.read_csv('data/train/scaled_X_train.csv',\n",
    "                      parse_dates=True, index_col='unix')\n",
    "y_train = pd.read_csv('data/train/y_train.csv',\n",
    "                      parse_dates=True, index_col='unix')\n",
    "X_test = pd.read_csv('data/test/scaled_X_test.csv',\n",
    "                     parse_dates=True, index_col='unix')\n",
    "y_test = pd.read_csv('data/test/y_test.csv',\n",
    "                     parse_dates=True, index_col='unix')\n",
    "X_val = pd.read_csv('data/val/scaled_X_val.csv',\n",
    "                    parse_dates=True, index_col='unix')\n",
    "y_val = pd.read_csv('data/val/y_val.csv', parse_dates=True, index_col='unix')\n",
    "\n",
    "# Calculate the weights for the imbalanced classes\n",
    "y = pd.concat([y_train, y_val, y_test])\n",
    "weights = cwts(y.values.flatten())\n",
    "\n",
    "# Metrics\n",
    "binary_accuracy = tf.keras.metrics.BinaryAccuracy()\n",
    "precision = tf.keras.metrics.Precision()\n",
    "recall = tf.keras.metrics.Recall()\n",
    "\n",
    "# Run the pipeline\n",
    "corr = RemoveCorPairwiseTransform()\n",
    "rf = RandomForestClassifier(n_jobs=-1, class_weight=weights)\n",
    "boruta = BorutaPy(rf, n_estimators='auto', verbose=2, perc=90)\n",
    "umap = UMAP(n_neighbors=10)\n",
    "pipe = Pipeline([('pairwisecorr', corr)], verbose=True)\n",
    "\n",
    "X_train_pipe = pipe.fit_transform(X_train, y_train.values.ravel())\n",
    "X_val_pipe = pipe.transform(X_val)\n",
    "\n",
    "# Calculate feature length\n",
    "featurelen = X_train_pipe.shape[-1]\n",
    "\n",
    "# An extension of the keras tuner HyperModel that allows for iterating over different model functions\n",
    "\n",
    "\n",
    "class IterableHyperModel(keras_tuner.HyperModel):\n",
    "    def __init__(self, inputs, model_func, name=None, tunable=True):\n",
    "        self.inputs = inputs\n",
    "        self.model_func = model_func\n",
    "\n",
    "    def build(self, hp):\n",
    "        # Define the hyperparameters\n",
    "        # Units\n",
    "        units_1 = hp.Int('units_1', min_value=16, max_value=512, step=16)\n",
    "        units_2 = hp.Int('units_2', min_value=16, max_value=512, step=16)\n",
    "        units_3 = hp.Int('units_3', min_value=16, max_value=512, step=16)\n",
    "        # Learning rate\n",
    "        lr = hp.Float('learning_rate', min_value=0.05, max_value=0.5)\n",
    "        # Dropout rate\n",
    "        dr = hp.Float('dropout_rate', min_value=0.01, max_value=0.8)\n",
    "        # Optimizer\n",
    "        hp_optimizer = hp.Choice('optimizer', ['adam', 'rmsprop', 'adagrad'])\n",
    "        if hp_optimizer == 'adam':\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "        elif hp_optimizer == 'rmsprop':\n",
    "            optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
    "        elif hp_optimizer == 'adagrad':\n",
    "            optimizer = tf.keras.optimizers.Adagrad(learning_rate=lr)\n",
    "\n",
    "        # Activations\n",
    "        activation_1 = hp.Choice(\n",
    "            'activation_1', ['relu', 'elu', 'tanh', 'sigmoid', 'selu'])\n",
    "        activation_2 = hp.Choice(\n",
    "            'activation_2', ['relu', 'elu', 'tanh', 'sigmoid', 'selu'])\n",
    "        activation_3 = hp.Choice(\n",
    "            'activation_3', ['relu', 'elu', 'tanh', 'sigmoid', 'selu'])\n",
    "\n",
    "        model = self.model_func(self.inputs, units_1, units_2, units_3, dr, optimizer, activation_1, activation_2, activation_3)\n",
    "        return model\n",
    "\n",
    "# Begin defining models\n",
    "# Three mayer model with dropout\n",
    "def two_layer_dropout(inputs, units_1, units_2, units_3, dr, optimizer, activation_1, activation_2, activation_3):\n",
    "            \n",
    "    # Initialise layers\n",
    "    x = tf.keras.layers.LSTM(units=units_1, activation=activation_1, dropout=dr, recurrent_dropout=dr,return_sequences=True, name='lstm-1-twolayer-dropout')(inputs)\n",
    "    x = tf.keras.layers.LSTM(units=units_2, activation=activation_2, dropout=dr, recurrent_dropout=dr,name='lstm-3-twolayer-dropout')(x)\n",
    "    outputs = tf.keras.layers.Dense(units=1, activation='sigmoid', name='dense-twolayer-dropout')(x)\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy',\n",
    "                      weighted_metrics=[binary_accuracy, precision, recall])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Define the sequence length and reshape the data into the correct array\n",
    "seqlen = 1\n",
    "name = 'two_layer_dropout'\n",
    "\n",
    "# Define the tensors\n",
    "train_tensors = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    X_train_pipe, y_train.iloc[seqlen-1:], seqlen)\n",
    "val_tensors = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    X_val_pipe, y_val.iloc[seqlen-1:], seqlen)\n",
    "\n",
    "# Define the input\n",
    "inputs = tf.keras.Input(shape=(seqlen, featurelen))\n",
    "\n",
    "# Define the file paths\n",
    "filepath = f'./tensorboard/model_tuning/{name}_{seqlen}_hour'\n",
    "modelpath = f'./models/model_tuning/{name}_{seqlen}_hour'\n",
    "\n",
    "# Define the callbacks\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        patience=10, monitor='val_binary_accuracy', mode='max'),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=filepath, histogram_freq=1),\n",
    "    tf.keras.callbacks.ModelCheckpoint(modelpath, monitor='val_binary_accuracy', save_best_only=True, mode='max')]\n",
    "\n",
    "# Initialise tuner and search\n",
    "\n",
    "tuner = keras_tuner.Hyperband(IterableHyperModel(inputs, two_layer_dropout), objective=keras_tuner.Objective(\n",
    "    'val_binary_accuracy', direction='max'), max_epochs=2, overwrite=True, directory=modelpath, seed=42, project_name=f'{name}_{seqlen}_hour')\n",
    "\n",
    "tuner.search(train_tensors, validation_data=val_tensors,\n",
    "             callbacks=callbacks, epochs=1000, class_weight=weights, use_multiprocessing=True, workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0001'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.oracle.get_best_trials()[0].trial_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm-1-twolayer-dropout will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm-1-twolayer-dropout will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm-3-twolayer-dropout will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm-3-twolayer-dropout will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm-1-twolayer-dropout will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm-1-twolayer-dropout will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm-3-twolayer-dropout will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm-3-twolayer-dropout will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n"
     ]
    }
   ],
   "source": [
    "for trial in tuner.oracle.get_best_trials(10):\n",
    "    model = tuner.load_model(trial)\n",
    "    model.save(f'{trial.trial_id}.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in ./models/model_tuning/two_layer_dropout_1_hour/two_layer_dropout_1_hour\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_binary_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 0001 summary\n",
      "Hyperparameters:\n",
      "units_1: 128\n",
      "units_2: 512\n",
      "units_3: 320\n",
      "learning_rate: 0.461139337649701\n",
      "dropout_rate: 0.08136848487278614\n",
      "optimizer: adagrad\n",
      "activation_1: relu\n",
      "activation_2: tanh\n",
      "activation_3: elu\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.23263157904148102\n",
      "\n",
      "Trial 0000 summary\n",
      "Hyperparameters:\n",
      "units_1: 336\n",
      "units_2: 32\n",
      "units_3: 224\n",
      "learning_rate: 0.17234393647284085\n",
      "dropout_rate: 0.7117317803974657\n",
      "optimizer: rmsprop\n",
      "activation_1: tanh\n",
      "activation_2: relu\n",
      "activation_3: tanh\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.22789473831653595\n"
     ]
    }
   ],
   "source": [
    "summary = tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm-1-twolayer-dropout will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm-1-twolayer-dropout will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm-3-twolayer-dropout will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm-3-twolayer-dropout will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm-1-twolayer-dropout will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm-1-twolayer-dropout will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm-3-twolayer-dropout will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm-3-twolayer-dropout will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n"
     ]
    }
   ],
   "source": [
    "model = tuner.get_best_models(num_models=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<keras.src.engine.functional.Functional object at 0x77af5dd3d2d0>, <keras.src.engine.functional.Functional object at 0x77ae61779b40>]\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'model',\n",
       " 'trainable': True,\n",
       " 'layers': [{'module': 'keras.layers',\n",
       "   'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, 1, 159),\n",
       "    'dtype': 'float32',\n",
       "    'sparse': False,\n",
       "    'ragged': False,\n",
       "    'name': 'input_1'},\n",
       "   'registered_name': None,\n",
       "   'name': 'input_1',\n",
       "   'inbound_nodes': []},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'LSTM',\n",
       "   'config': {'name': 'lstm-1-twolayer-dropout',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'return_sequences': True,\n",
       "    'return_state': False,\n",
       "    'go_backwards': False,\n",
       "    'stateful': False,\n",
       "    'unroll': False,\n",
       "    'time_major': False,\n",
       "    'units': 128,\n",
       "    'activation': 'relu',\n",
       "    'recurrent_activation': 'sigmoid',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None},\n",
       "     'registered_name': None},\n",
       "    'recurrent_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'Orthogonal',\n",
       "     'config': {'gain': 1.0, 'seed': None},\n",
       "     'registered_name': None},\n",
       "    'bias_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'Zeros',\n",
       "     'config': {},\n",
       "     'registered_name': None},\n",
       "    'unit_forget_bias': True,\n",
       "    'kernel_regularizer': None,\n",
       "    'recurrent_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'recurrent_constraint': None,\n",
       "    'bias_constraint': None,\n",
       "    'dropout': 0.08136848487278614,\n",
       "    'recurrent_dropout': 0.08136848487278614,\n",
       "    'implementation': 1},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 1, 159)},\n",
       "   'name': 'lstm-1-twolayer-dropout',\n",
       "   'inbound_nodes': [[['input_1', 0, 0, {}]]]},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'LSTM',\n",
       "   'config': {'name': 'lstm-3-twolayer-dropout',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'return_sequences': False,\n",
       "    'return_state': False,\n",
       "    'go_backwards': False,\n",
       "    'stateful': False,\n",
       "    'unroll': False,\n",
       "    'time_major': False,\n",
       "    'units': 512,\n",
       "    'activation': 'tanh',\n",
       "    'recurrent_activation': 'sigmoid',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None},\n",
       "     'registered_name': None},\n",
       "    'recurrent_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'Orthogonal',\n",
       "     'config': {'gain': 1.0, 'seed': None},\n",
       "     'registered_name': None},\n",
       "    'bias_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'Zeros',\n",
       "     'config': {},\n",
       "     'registered_name': None},\n",
       "    'unit_forget_bias': True,\n",
       "    'kernel_regularizer': None,\n",
       "    'recurrent_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'recurrent_constraint': None,\n",
       "    'bias_constraint': None,\n",
       "    'dropout': 0.08136848487278614,\n",
       "    'recurrent_dropout': 0.08136848487278614,\n",
       "    'implementation': 1},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 1, 128)},\n",
       "   'name': 'lstm-3-twolayer-dropout',\n",
       "   'inbound_nodes': [[['lstm-1-twolayer-dropout', 0, 0, {}]]]},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'Dense',\n",
       "   'config': {'name': 'dense-twolayer-dropout',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 1,\n",
       "    'activation': 'sigmoid',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None},\n",
       "     'registered_name': None},\n",
       "    'bias_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'Zeros',\n",
       "     'config': {},\n",
       "     'registered_name': None},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 512)},\n",
       "   'name': 'dense-twolayer-dropout',\n",
       "   'inbound_nodes': [[['lstm-3-twolayer-dropout', 0, 0, {}]]]}],\n",
       " 'input_layers': [['input_1', 0, 0]],\n",
       " 'output_layers': [['dense-twolayer-dropout', 0, 0]]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].get_config()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_assignment_code-eTELY0YF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
